{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from IPython.display import HTML\n",
    "alt.renderers.enable('notebook')\n",
    "directory = '../data/json_news_by_years_classified'\n",
    "output_dir = '../data/csv_grouped_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_model(dataframe, interval_width = 0.99, changepoint_range = 0.8):\n",
    "    m = Prophet(daily_seasonality = False, yearly_seasonality = False, weekly_seasonality = False,\n",
    "                seasonality_mode = 'multiplicative', \n",
    "                interval_width = interval_width,\n",
    "                changepoint_range = changepoint_range)\n",
    "    m = m.fit(dataframe)\n",
    "    forecast = m.predict(dataframe)\n",
    "    forecast['fact'] = dataframe['y'].reset_index(drop = True)\n",
    "    return forecast\n",
    "\n",
    "def detect_anomalies(forecast):\n",
    "    forecasted = forecast[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper', 'fact']].copy()\n",
    "    #forecast['fact'] = df['y']\n",
    "\n",
    "    forecasted['anomaly'] = 0\n",
    "    forecasted.loc[forecasted['fact'] > forecasted['yhat_upper'], 'anomaly'] = 1\n",
    "    forecasted.loc[forecasted['fact'] < forecasted['yhat_lower'], 'anomaly'] = -1\n",
    "\n",
    "    #anomaly importances\n",
    "    forecasted['importance'] = 0\n",
    "    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n",
    "        (forecasted['fact'] - forecasted['yhat_upper'])/forecast['fact']\n",
    "    forecasted.loc[forecasted['anomaly'] ==-1, 'importance'] = \\\n",
    "        (forecasted['yhat_lower'] - forecasted['fact'])/forecast['fact']\n",
    "    \n",
    "    return forecasted\n",
    "\n",
    "def plot_anomalies(forecasted):\n",
    "    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color = '#7FC97F').encode(\n",
    "    x=alt.X('ds:T',  title ='date'),\n",
    "    y='yhat_upper',\n",
    "    y2='yhat_lower',\n",
    "    tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper']\n",
    "    ).interactive().properties(\n",
    "        title='Anomaly Detection'\n",
    "    )\n",
    "\n",
    "    fact = alt.Chart(forecasted[forecasted.anomaly==0]).mark_circle(size=15, opacity=0.7, color = 'Black').encode(\n",
    "        x='ds:T',\n",
    "        y=alt.Y('fact', title='sales'),    \n",
    "        tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper']\n",
    "    ).interactive()\n",
    "\n",
    "    anomalies = alt.Chart(forecasted[forecasted.anomaly!=0]).mark_circle(size=30, color = 'Red').encode(\n",
    "        x='ds:T',\n",
    "        y=alt.Y('fact', title='sales'),    \n",
    "        tooltip=['ds', 'fact', 'yhat_lower', 'yhat_upper'],\n",
    "        size = alt.Size( 'importance', legend=None)\n",
    "    ).interactive()\n",
    "\n",
    "    return alt.layer(interval, fact, anomalies)\\\n",
    "              .properties(width=870, height=450)\\\n",
    "              .configure_title(fontSize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print(\"loading news\")\n",
    "    df = pd.read_csv(output_dir+\"/grouped_data_day_mean.csv\", sep=\";\")\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loading news\n                normalised_date    Unnamed: 0  crime_probability  sentiment  \\\n0     2005-01-01 00:00:00+00:00   9855.000000           0.166289   0.166884   \n1     2005-01-02 00:00:00+00:00   9828.000000           0.138094   0.283870   \n2     2005-01-03 00:00:00+00:00   9801.000000           0.123617   0.170715   \n3     2005-01-04 00:00:00+00:00   9774.000000           0.202801   0.075195   \n4     2005-01-05 00:00:00+00:00   9747.000000           0.207076   0.147576   \n...                         ...           ...                ...        ...   \n5590  2020-05-02 00:00:00+00:00  50057.042965           0.063573   0.195940   \n5591  2020-05-03 00:00:00+00:00  50934.437220           0.074751   0.192142   \n5592  2020-05-04 00:00:00+00:00  51954.621723           0.057100   0.204034   \n5593  2020-05-05 00:00:00+00:00  53333.553621           0.079166   0.185626   \n5594  2020-05-06 00:00:00+00:00  53567.359551           0.017864   0.168754   \n\n      probability_domestic_violence  talks_about_domestic_violence  \\\n0                          0.145316                       0.111111   \n1                          0.118793                       0.074074   \n2                          0.115977                       0.074074   \n3                          0.146209                       0.074074   \n4                          0.093871                       0.074074   \n...                             ...                            ...   \n5590                       0.077276                       0.046187   \n5591                       0.079871                       0.051570   \n5592                       0.080737                       0.053184   \n5593                       0.072975                       0.045265   \n5594                       0.049618                       0.033708   \n\n      talks_about_domestic_violence_and_are_sad  \n0                                      0.111111  \n1                                      0.074074  \n2                                      0.037037  \n3                                      0.074074  \n4                                      0.037037  \n...                                         ...  \n5590                                   0.042965  \n5591                                   0.038117  \n5592                                   0.039700  \n5593                                   0.036212  \n5594                                   0.022472  \n\n[5595 rows x 7 columns]\n      crime_probability normalised_date\n0              0.166289      2005-01-01\n1              0.138094      2005-01-02\n2              0.123617      2005-01-03\n3              0.202801      2005-01-04\n4              0.207076      2005-01-05\n...                 ...             ...\n5590           0.063573      2020-05-02\n5591           0.074751      2020-05-03\n5592           0.057100      2020-05-04\n5593           0.079166      2020-05-05\n5594           0.017864      2020-05-06\n\n[5595 rows x 2 columns]\n"
    }
   ],
   "source": [
    "df = load_data()\n",
    "df = df[[\"crime_probability\", \"normalised_date\"]]\n",
    "df['normalised_date'] = pd.to_datetime(df['normalised_date'])\n",
    "df['normalised_date'] = df['normalised_date'].dt.tz_convert(None)\n",
    "print(df)\n",
    "df.columns = ['y', 'ds']\n",
    "pred = fit_predict_model(df)\n",
    "pred = detect_anomalies(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = plot_anomalies(pred.tail(4000))\n",
    "plot.save('chart.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitpapercrimetdapipenv0865a9216fa446c8a4c54843e55fe5ba",
   "display_name": "Python 3.7.4 64-bit ('paper_crime_tda': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}